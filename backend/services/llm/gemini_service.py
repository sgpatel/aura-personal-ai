# backend/services/llm/gemini_service.py
import logging
from typing import List, Dict, Any
import google.generativeai as genai # Import the library

from .base import LLMService
from backend.core.config import settings # To potentially access model specifics later

logger = logging.getLogger(__name__)

class GeminiLLMService(LLMService):
    provider = "gemini"

    def __init__(self, api_key: str):
        try:
            genai.configure(api_key=api_key)
            # Initialize the model - choose appropriate model (e.g., 'gemini-pro' or newer)
            self.model = genai.GenerativeModel('gemini-1.5-flash') # Or 'gemini-pro', 'gemini-1.5-pro' etc.
            logger.info(f"Google Generative AI client configured successfully for model: {self.model.model_name}")
        except Exception as e:
            logger.error(f"Failed to configure Google Generative AI: {e}", exc_info=True)
            self.model = None

    def _handle_api_error(self, error: Exception, context: str) -> str:
        # TODO: Add more specific error handling for google.api_core.exceptions
        logger.error(f"Google Gemini API Error ({context}): {error}", exc_info=True)
        # Specific error types might include BlockedPromptException, RateLimitExceeded, etc.
        return f"[Error: Google Gemini API request failed. {error}]"

    def generate_text(self, prompt: str, **kwargs) -> str:
        """Generates simple text completion using Gemini."""
        if not self.model: return "[Error: Google Gemini client not initialized]"
        logger.info(f"Generating text with Google Gemini model: {self.model.model_name}")
        try:
            # Simple text generation
            response = self.model.generate_content(prompt)
            # Handle potential safety blocks or empty responses
            if response.parts:
                return response.text # Access generated text directly
            elif response.prompt_feedback.block_reason:
                 logger.warning(f"Gemini text generation blocked: {response.prompt_feedback.block_reason}")
                 return f"[Content blocked by safety settings: {response.prompt_feedback.block_reason}]"
            else:
                 logger.warning("Gemini response was empty or missing parts.")
                 return "[Error: No text generated by Gemini]"

        except Exception as e:
            return self._handle_api_error(e, "text generation")

    def generate_summary(self, documents: List[str], **kwargs) -> str:
        """Generates a summary from documents using Gemini."""
        if not self.model: return "[Error: Google Gemini client not initialized]"
        if not documents: return "No documents provided for summarization."

        full_text = "\n\n---\n\n".join(documents)
        # Adjust prompt for Gemini
        prompt = f"Summarize the following document(s):\n\n{full_text}\n\nSummary:"

        logger.info(f"Generating summary with Google Gemini model: {self.model.model_name}")
        try:
            response = self.model.generate_content(prompt)
            if response.parts:
                return response.text
            elif response.prompt_feedback.block_reason:
                 logger.warning(f"Gemini summary generation blocked: {response.prompt_feedback.block_reason}")
                 return f"[Summary blocked by safety settings: {response.prompt_feedback.block_reason}]"
            else:
                 logger.warning("Gemini summary response was empty or missing parts.")
                 return "[Error: No summary generated by Gemini]"

        except Exception as e:
            return self._handle_api_error(e, "summarization")
